/**
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 * IDENTITY LOCK PIPELINE
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 *
 * State-of-the-art identity locking system using InstantID + IP-Adapter.
 * This is the core technology that ensures every generated image of a persona
 * has the EXACT SAME FACE while allowing style/expression variation.
 *
 * PIPELINE:
 * â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 * â”‚                        IDENTITY LOCK PIPELINE                               â”‚
 * â”‚                                                                             â”‚
 * â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
 * â”‚  â”‚  1. INPUT   â”‚â”€â”€â”€â–¶â”‚ 2. EXTRACT  â”‚â”€â”€â”€â–¶â”‚  3. EMBED   â”‚â”€â”€â”€â–¶â”‚  4. LOCK    â”‚ â”‚
 * â”‚  â”‚   Image     â”‚    â”‚   Face      â”‚    â”‚   Identity  â”‚    â”‚   Forever   â”‚ â”‚
 * â”‚  â”‚             â”‚    â”‚ InsightFace â”‚    â”‚  InstantID  â”‚    â”‚   Store     â”‚ â”‚
 * â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
 * â”‚                                                                             â”‚
 * â”‚  POST-LOCK: Any generation uses locked embedding â†’ SAME FACE GUARANTEED    â”‚
 * â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 *
 * TECHNOLOGIES:
 * - InsightFace (antelopev2): Face detection & embedding extraction
 * - InstantID: Zero-shot identity-preserving generation
 * - IP-Adapter: Style embedding for consistent aesthetics
 * - ControlNet: Pose/expression control
 *
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 */

import type {
    FaceEmbedding,
    StyleEmbedding,
    ExpressionGrid,
    ExpressionAsset,
    NormalizedFloat,
    VisualDNA,
    PersonaGenome,
  } from './types';

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // PIXAR-QUALITY IMAGE GENERATION PRESETS
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  //
  // "Make something wonderful and put it out there." â€” Steve Jobs
  //
  // These presets define the exact parameters for Pixar-quality image generation.
  // Each preset is carefully tuned for optimal FLUX output.
  //
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  export const IMAGE_QUALITY_PRESETS = {
    // Fast preview for iteration
    draft: {
      steps: 15,
      cfgScale: 3.5,
      width: 768,
      height: 768,
      sampler: "euler",
      scheduler: "normal",
    },
    // Balanced quality/speed for most use cases
    standard: {
      steps: 28,
      cfgScale: 3.5,
      width: 1024,
      height: 1024,
      sampler: "euler",
      scheduler: "normal",
    },
    // High quality for final output
    high: {
      steps: 40,
      cfgScale: 3.5,
      width: 1024,
      height: 1024,
      sampler: "dpmpp_2m",
      scheduler: "karras",
    },
    // Pixar-quality for hero images
    pixar: {
      steps: 50,
      cfgScale: 3.5,
      width: 1024,
      height: 1024,
      sampler: "dpmpp_2m_sde",
      scheduler: "karras",
    },
    // Cinema-quality for maximum fidelity
    cinema: {
      steps: 75,
      cfgScale: 3.5,
      width: 1024,
      height: 1024,
      sampler: "dpmpp_2m_sde",
      scheduler: "karras",
    },
  } as const;

  export type ImageQualityPreset = keyof typeof IMAGE_QUALITY_PRESETS;

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // PIXAR-QUALITY STYLE PROMPTS - The Soul of Visual Generation
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  export const PIXAR_STYLE_PROMPTS = {
    // The core Pixar aesthetic - friendly, appealing, full of life
    pixar_3d: `masterpiece, pixar style, disney pixar 3d render, stunning character portrait, octane render, unreal engine 5, soft subsurface scattering, beautiful expressive eyes with catchlights, smooth flawless skin texture, gentle ambient occlusion, professional studio lighting with rim light, detailed face with appealing proportions, warm inviting expression, friendly character design, high detail, 8k resolution, photorealistic rendering`,

    // Arcane/League of Legends stylized look
    arcane_stylized: `masterpiece, arcane league of legends style, fortiche production, stylized painterly portrait, dramatic volumetric lighting, expressive detailed face, sharp features, glowing eyes, painterly brush strokes, cinematic color grading, detailed textures, atmospheric, moody lighting, professional digital art, trending on artstation, 8k ultra detailed`,

    // Premium anime aesthetic
    anime_premium: `masterpiece, best quality, ultra detailed anime portrait, beautiful detailed eyes with reflections, sharp linework, professional anime style, studio quality, soft shading, beautiful lighting, detailed hair, expressive face, clean background, trending on pixiv, professional illustration`,

    // Hyperrealistic photographic quality
    hyper_realistic: `masterpiece, hyperrealistic portrait photography, shot on hasselblad h6d-400c, zeiss otus 85mm f/1.4, professional studio lighting setup, octane render, subsurface scattering, detailed skin pores and texture, sharp focus on eyes, shallow depth of field, 8k resolution, RAW photo, photorealistic, award winning portrait photography`,

    // Epic fantasy character
    fantasy_epic: `masterpiece, epic fantasy character portrait, dramatic cinematic lighting, magical atmosphere, detailed ornate costume, mystical aura effects, professional concept art, trending on artstation, by greg rutkowski and ross tran, 8k ultra detailed, volumetric lighting`,

    // Clean corporate professional look
    corporate_professional: `masterpiece, professional business headshot, clean white or gray background, soft studio lighting, professional attire, confident approachable expression, linkedin profile quality, corporate photography style, sharp focus, high detail, professional retouching`,
  } as const;

  export type PixarStylePreset = keyof typeof PIXAR_STYLE_PROMPTS;

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // TYPES
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  /**
   * GPU Provider configuration
   */
  export interface GPUProviderConfig {
    provider: 'runpod' | 'modal' | 'fal' | 'together';
    apiKey: string;
    baseUrl?: string;
    /** Timeout in ms */
    timeout?: number;
    /** Max retries on failure */
    maxRetries?: number;
    /** Quality preset for image generation */
    qualityPreset?: ImageQualityPreset;
  }
  
  /**
   * Face detection result from InsightFace
   */
  export interface FaceDetectionResult {
    /** Bounding box [x, y, width, height] */
    bbox: [number, number, number, number];
    /** Facial landmarks (5 points) */
    landmarks: number[][];
    /** Detection confidence */
    confidence: number;
    /** 512-dim face embedding */
    embedding: number[];
    /** Face age estimation */
    age?: number;
    /** Face gender estimation */
    gender?: 'male' | 'female';
  }
  
  /**
   * Image generation request
   */
  export interface GenerationRequest {
    /** Text prompt */
    prompt: string;
    /** Negative prompt */
    negativePrompt?: string;
    /** Face embedding for identity */
    faceEmbedding?: number[];
    /** Style embedding */
    styleEmbedding?: number[];
    /** Reference image URL (for IP-Adapter) */
    referenceImageUrl?: string;
    /** Generation parameters */
    params?: {
      width?: number;
      height?: number;
      steps?: number;
      cfgScale?: number;
      sampler?: string;
      seed?: number;
      /** InstantID strength (0-1) */
      identityStrength?: number;
      /** IP-Adapter strength (0-1) */
      styleStrength?: number;
    };
  }
  
  /**
   * Generation result
   */
  export interface GenerationResult {
    /** Generated image URL */
    imageUrl: string;
    /** Seed used */
    seed: number;
    /** Generation time in ms */
    generationTimeMs: number;
    /** Cost in USD */
    cost: number;
    /** NSFW score if checked */
    nsfwScore?: number;
  }
  
  /**
   * Expression generation request
   */
  export interface ExpressionRequest {
    /** Base identity embedding */
    faceEmbedding: number[];
    /** Style embedding */
    styleEmbedding?: number[];
    /** Emotion to generate */
    emotion: string;
    /** Base prompt additions */
    basePrompt: string;
    /** Locked negative prompt */
    negativePrompt: string;
  }
  
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // GPU PROVIDER ABSTRACTION
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  
  /**
   * Abstract GPU provider interface
   * Allows switching between RunPod, Modal, Fal, etc.
   */
  export abstract class GPUProvider {
    protected config: GPUProviderConfig;
  
    constructor(config: GPUProviderConfig) {
      this.config = config;
    }
  
    /** Extract face embedding from image */
    abstract extractFaceEmbedding(imageUrl: string): Promise<FaceDetectionResult>;
  
    /** Generate image with InstantID */
    abstract generateWithIdentity(request: GenerationRequest): Promise<GenerationResult>;
  
    /** Generate batch of images */
    abstract generateBatch(requests: GenerationRequest[]): Promise<GenerationResult[]>;
  
    /** Check provider health/availability */
    abstract healthCheck(): Promise<boolean>;
  
    /** Get current queue depth */
    abstract getQueueDepth(): Promise<number>;
  }
  
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // RUNPOD PROVIDER â€” ComfyUI Serverless
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  //
  // Uses ComfyUI workflow API on RunPod serverless.
  // Endpoint ID configured via RUNPOD_ENDPOINT_ID env var.
  //
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  export class RunPodProvider extends GPUProvider {
    private readonly baseUrl: string;
    private readonly endpointId: string;

    constructor(config: GPUProviderConfig) {
      super(config);
      this.endpointId = config.baseUrl || process.env.RUNPOD_ENDPOINT_ID || '';
      this.baseUrl = `https://api.runpod.ai/v2/${this.endpointId}`;
    }

    async extractFaceEmbedding(imageUrl: string): Promise<FaceDetectionResult> {
      // ComfyUI doesn't have built-in face extraction
      // Return a placeholder - face embedding handled by reference image in generation
      console.log('[RunPod] Face extraction not available in ComfyUI, using reference image directly');
      return {
        bbox: [0, 0, 512, 512],
        landmarks: [],
        confidence: 1.0,
        embedding: [],
        age: undefined,
        gender: undefined,
      };
    }

    async generateWithIdentity(request: GenerationRequest): Promise<GenerationResult> {
      const startTime = Date.now();
      const seed = request.params?.seed || Math.floor(Math.random() * 2147483647);

      console.log('[RunPod] Generating with ComfyUI SDXL...');
      console.log(`[RunPod] Endpoint: ${this.endpointId}`);

      // Retry logic for cold starts - first few generations may return blank
      const MAX_RETRIES = 3;
      let lastResult: GenerationResult | null = null;

      for (let attempt = 1; attempt <= MAX_RETRIES; attempt++) {
        const result = await this._generateWithIdentityAttempt(request, seed + (attempt - 1), startTime, attempt);
        lastResult = result;

        // Check if image is blank (all null bytes after PNG header)
        if (this.isImageBlank(result.imageUrl)) {
          console.warn(`[RunPod] Attempt ${attempt}/${MAX_RETRIES}: Got blank image, model may be loading...`);
          if (attempt < MAX_RETRIES) {
            // Wait a bit longer for cold start
            await new Promise(r => setTimeout(r, 3000 * attempt));
            continue;
          }
          console.error('[RunPod] All retries returned blank images - model may not be loaded');
        }

        // Image is valid, return it
        return result;
      }

      return lastResult!;
    }

    /**
     * Check if a base64 image is blank (all zeros after header)
     */
    private isImageBlank(imageUrl: string): boolean {
      if (!imageUrl.startsWith('data:image')) return false;

      // Extract base64 data
      const base64Data = imageUrl.split(',')[1];
      if (!base64Data || base64Data.length < 200) return true;

      // Check if data after PNG header is mostly zeros (AAAA in base64 = null bytes)
      // Look at bytes 100-200 of the base64 data - should have variation if real image
      const sampleSection = base64Data.substring(100, 200);
      const uniqueChars = new Set(sampleSection).size;

      // A real image will have variety; blank image will be mostly 'A' (null bytes)
      if (uniqueChars < 5) {
        console.log(`[RunPod] Blank image detected: only ${uniqueChars} unique chars in sample`);
        return true;
      }

      return false;
    }

    private async _generateWithIdentityAttempt(
      request: GenerationRequest,
      seed: number,
      startTime: number,
      attempt: number
    ): Promise<GenerationResult> {
      if (attempt > 1) {
        console.log(`[RunPod] Retry attempt ${attempt}...`);
      }

      // ComfyUI FLUX workflow (FLUX uses different settings than SDXL!)
      const workflow = this.buildSDXLWorkflow({
        prompt: request.prompt,
        negativePrompt: '', // FLUX ignores negative prompts - leave empty!
        width: request.params?.width || 1024,
        height: request.params?.height || 1024,
        steps: request.params?.steps || 28, // FLUX quality: 28 steps
        cfgScale: request.params?.cfgScale || 3.5, // FLUX: 1.0-3.5, NOT 7-9!
        seed,
      });

      const response = await fetch(`${this.baseUrl}/run`, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${this.config.apiKey}`,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          input: {
            workflow,
          },
        }),
      });

      if (!response.ok) {
        const error = await response.text();
        throw new Error(`RunPod ComfyUI request failed: ${response.status} - ${error}`);
      }

      const result = await response.json();
      console.log(`[RunPod] Job submitted: ${result.id}`);

      const jobResult = await this.pollForCompletion(result.id);

      // Extract image from ComfyUI output - handle various formats
      let imageUrl = '';
      const output = jobResult.output;

      console.log('[RunPod] Raw output:', JSON.stringify(output, null, 2).substring(0, 500));

      // ComfyUI returns images with base64 data
      if (output?.images && Array.isArray(output.images)) {
        const img = output.images[0];
        console.log('[RunPod] Image object keys:', Object.keys(img || {}));
        console.log('[RunPod] img.data exists:', !!img?.data, 'type:', typeof img?.data);
        // Priority: data (base64) > url > image > filename
        if (img?.data) {
          // Base64 encoded image data
          imageUrl = `data:image/png;base64,${img.data}`;
          console.log('[RunPod] Using base64 image data');
        } else if (typeof img === 'string') {
          imageUrl = img;
        } else if (img?.url) {
          imageUrl = img.url;
        } else if (img?.image) {
          imageUrl = img.image;
        } else if (img?.filename) {
          imageUrl = img.filename;
        }
      } else if (output?.message) {
        imageUrl = typeof output.message === 'string' ? output.message : JSON.stringify(output.message);
      } else if (typeof output === 'string') {
        imageUrl = output;
      } else if (output?.image) {
        imageUrl = output.image;
      } else if (output?.url) {
        imageUrl = output.url;
      }

      // Handle raw base64 without prefix
      if (imageUrl && !imageUrl.startsWith('http') && !imageUrl.startsWith('data:')) {
        if (imageUrl.length > 1000) {
          imageUrl = `data:image/png;base64,${imageUrl}`;
        }
      }

      const generationTimeMs = Date.now() - startTime;
      console.log(`[RunPod] ComfyUI complete in ${generationTimeMs}ms`);
      console.log(`[RunPod] Image URL (first 100 chars): ${String(imageUrl).substring(0, 100)}`);

      return {
        imageUrl,
        seed,
        generationTimeMs,
        cost: this.calculateCost(jobResult.executionTime || generationTimeMs),
      };
    }

    /**
     * Build Flux workflow for ComfyUI
     * Uses flux1-dev-fp8.safetensors (fast, high quality)
     *
     * CRITICAL: Positive and negative prompts must use DIFFERENT nodes!
     *
     * Supports Pixar-quality presets with advanced samplers.
     */
    private buildSDXLWorkflow(params: {
      prompt: string;
      negativePrompt: string;
      width: number;
      height: number;
      steps: number;
      cfgScale: number;
      seed: number;
      sampler?: string;
      scheduler?: string;
    }): object {
      // Default to euler if not specified (works best for FLUX)
      const samplerName = params.sampler || "euler";
      const schedulerName = params.scheduler || "normal";

      // Flux workflow with proper positive/negative conditioning
      return {
        // Load Flux checkpoint (base model)
        "4": {
          "class_type": "CheckpointLoaderSimple",
          "inputs": {
            "ckpt_name": "flux1-dev-fp8.safetensors"
          }
        },
        // Empty latent for image generation
        "5": {
          "class_type": "EmptyLatentImage",
          "inputs": {
            "batch_size": 1,
            "height": params.height,
            "width": params.width
          }
        },
        // POSITIVE prompt encoding
        "6": {
          "class_type": "CLIPTextEncode",
          "inputs": {
            "clip": ["4", 1],
            "text": params.prompt
          }
        },
        // NEGATIVE prompt encoding - SEPARATE NODE!
        "7": {
          "class_type": "CLIPTextEncode",
          "inputs": {
            "clip": ["4", 1],
            "text": params.negativePrompt
          }
        },
        // KSampler with quality preset sampler/scheduler
        "3": {
          "class_type": "KSampler",
          "inputs": {
            "cfg": params.cfgScale,
            "denoise": 1,
            "latent_image": ["5", 0],
            "model": ["4", 0],
            "negative": ["7", 0],  // Uses node 7 (negative prompt)
            "positive": ["6", 0],  // Uses node 6 (positive prompt)
            "sampler_name": samplerName,  // Pixar: dpmpp_2m_sde
            "scheduler": schedulerName,   // Pixar: karras
            "seed": params.seed,
            "steps": params.steps
          }
        },
        // Decode latent to image
        "8": {
          "class_type": "VAEDecode",
          "inputs": {
            "samples": ["3", 0],
            "vae": ["4", 2]
          }
        },
        // Save image
        "9": {
          "class_type": "SaveImage",
          "inputs": {
            "filename_prefix": "persona",
            "images": ["8", 0]
          }
        }
      };
    }

    async generateBatch(requests: GenerationRequest[]): Promise<GenerationResult[]> {
      // Run sequentially for ComfyUI to avoid overloading
      const results: GenerationResult[] = [];
      for (const req of requests) {
        const result = await this.generateWithIdentity(req);
        results.push(result);
      }
      return results;
    }

    async healthCheck(): Promise<boolean> {
      try {
        const response = await fetch(`${this.baseUrl}/health`, {
          headers: { 'Authorization': `Bearer ${this.config.apiKey}` },
        });
        return response.ok;
      } catch {
        return false;
      }
    }

    async getQueueDepth(): Promise<number> {
      return 0;
    }

    private async pollForCompletion(jobId: string, maxAttempts = 120): Promise<any> {
      console.log(`[RunPod] Polling job ${jobId}...`);

      for (let i = 0; i < maxAttempts; i++) {
        const response = await fetch(`${this.baseUrl}/status/${jobId}`, {
          headers: { 'Authorization': `Bearer ${this.config.apiKey}` },
        });

        const status = await response.json();

        if (status.status === 'COMPLETED') {
          console.log(`[RunPod] Job ${jobId} completed`);
          return status;
        }

        if (status.status === 'FAILED') {
          console.error(`[RunPod] Job ${jobId} failed:`, status.error);
          throw new Error(`ComfyUI job failed: ${status.error}`);
        }

        if (status.status === 'IN_QUEUE') {
          if (i % 10 === 0) console.log(`[RunPod] Job ${jobId} in queue...`);
        }

        if (status.status === 'IN_PROGRESS') {
          if (i % 10 === 0) console.log(`[RunPod] Job ${jobId} in progress...`);
        }

        await new Promise((r) => setTimeout(r, 1000));
      }

      throw new Error(`ComfyUI job timed out after ${maxAttempts} seconds`);
    }

    private calculateCost(executionTimeMs: number): number {
      // RunPod A40 pricing: ~$0.00044 per second
      return (executionTimeMs / 1000) * 0.00044;
    }
  }
  
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // IDENTITY LOCK PIPELINE
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  
  /**
   * Configuration for the Identity Lock Pipeline
   */
  export interface IdentityLockConfig {
    /** Primary GPU provider */
    primaryProvider: GPUProvider;
    /** Fallback GPU provider (optional) */
    fallbackProvider?: GPUProvider;
    /** Storage for generated assets */
    storage: {
      upload: (buffer: Buffer, filename: string) => Promise<string>;
      getPublicUrl: (key: string) => string;
    };
    /** Generation settings */
    settings?: {
      /** Number of initial variations to generate */
      initialVariations?: number;
      /** Number of expression variations per emotion */
      expressionVariations?: number;
      /** Default image dimensions */
      defaultWidth?: number;
      defaultHeight?: number;
    };
  }
  
  /**
   * The main Identity Lock Pipeline
   *
   * This is the core system that:
   * 1. Extracts facial identity from a source image
   * 2. Creates a locked identity embedding
   * 3. Generates consistent images using that identity
   * 4. Creates a full expression grid for the persona
   */
  export class IdentityLockPipeline {
    private readonly config: IdentityLockConfig;
    private readonly settings: Required<NonNullable<IdentityLockConfig['settings']>>;
  
    constructor(config: IdentityLockConfig) {
      this.config = config;
      this.settings = {
        initialVariations: config.settings?.initialVariations ?? 4,
        expressionVariations: config.settings?.expressionVariations ?? 1,
        defaultWidth: config.settings?.defaultWidth ?? 1024,
        defaultHeight: config.settings?.defaultHeight ?? 1024,
      };
    }
  
    /**
     * STEP 1: Generate initial character variations
     *
     * Creates multiple variations for the user to choose from.
     * No identity lock yet - these are fresh generations.
     */
    async generateInitialVariations(
      description: string,
      stylePreset: string,
      options?: {
        count?: number;
        customPrompt?: string;
        negativePrompt?: string;
      }
    ): Promise<GenerationResult[]> {
      const count = options?.count || this.settings.initialVariations;
  
      const prompt = this.buildCharacterPrompt(description, stylePreset, options?.customPrompt);
      const negativePrompt = options?.negativePrompt || this.getDefaultNegativePrompt(stylePreset);
  
      const requests: GenerationRequest[] = Array.from({ length: count }, () => ({
        prompt,
        negativePrompt: '', // FLUX ignores negative prompts
        params: {
          width: this.settings.defaultWidth,
          height: this.settings.defaultHeight,
          steps: 28, // FLUX quality steps
          cfgScale: 3.5, // FLUX optimal (NOT 7.5!)
          // Different seeds for variation
          seed: Math.floor(Math.random() * 2147483647),
        },
      }));
  
      return this.config.primaryProvider.generateBatch(requests);
    }
  
    /**
     * STEP 2: Lock Identity
     *
     * This is the KEY STEP. Extracts the face embedding from the chosen image
     * and creates the locked identity that will be used for all future generations.
     */
    async lockIdentity(
      chosenImageUrl: string,
      stylePrompt?: string
    ): Promise<{
      faceEmbedding: FaceEmbedding;
      styleEmbedding: StyleEmbedding;
    }> {
      console.log('ğŸ” Locking identity from chosen image...');
  
      // Extract face embedding
      const faceResult = await this.config.primaryProvider.extractFaceEmbedding(chosenImageUrl);
  
      if (faceResult.confidence < 0.8) {
        throw new Error(`Face detection confidence too low: ${faceResult.confidence}. Please choose a clearer image.`);
      }
  
      const faceEmbedding: FaceEmbedding = {
        vector: faceResult.embedding,
        model: 'insightface_antelopev2',
        sourceImageUrl: chosenImageUrl,
        confidence: faceResult.confidence,
        createdAt: new Date().toISOString(),
      };
  
      // Create style embedding (can be enhanced with IP-Adapter extraction)
      const styleEmbedding: StyleEmbedding = {
        vector: [], // Will be populated by IP-Adapter if used
        stylePrompt: stylePrompt,
        negativePrompt: this.getDefaultNegativePrompt('custom'),
      };
  
      console.log('âœ… Identity locked successfully!');
      console.log(`   Face confidence: ${faceResult.confidence}`);
      console.log(`   Embedding dimensions: ${faceResult.embedding.length}`);
  
      return { faceEmbedding, styleEmbedding };
    }
  
    /**
     * STEP 3: Generate Expression Grid
     *
     * Creates a full set of emotion expressions using the locked identity.
     * This pre-generates all expressions for instant switching during interactions.
     */
    async generateExpressionGrid(
      faceEmbedding: FaceEmbedding,
      styleEmbedding: StyleEmbedding,
      basePrompt: string,
      options?: {
        emotions?: string[];
        variations?: number;
      }
    ): Promise<ExpressionGrid> {
      const emotions = options?.emotions || [
        'neutral',
        'happy',
        'sad',
        'angry',
        'surprised',
        'thoughtful',
      ];
  
      console.log(`ğŸ­ Generating expression grid for ${emotions.length} emotions...`);
  
      const expressionPrompts: Record<string, string> = {
        neutral: 'neutral expression, calm, composed, direct gaze',
        happy: 'happy expression, warm genuine smile, joyful eyes, friendly',
        sad: 'sad expression, downcast eyes, slight frown, melancholic',
        angry: 'angry expression, furrowed brow, intense eyes, stern',
        surprised: 'surprised expression, wide eyes, raised eyebrows, amazed',
        thoughtful: 'thoughtful expression, contemplative, slight head tilt, pondering',
        excited: 'excited expression, bright eyes, big smile, enthusiastic',
        concerned: 'concerned expression, worried eyes, empathetic, caring',
        confident: 'confident expression, assured smile, strong gaze, self-assured',
        curious: 'curious expression, inquisitive look, slightly raised eyebrow',
        loving: 'loving expression, soft warm eyes, gentle smile, affectionate',
        disappointed: 'disappointed expression, slight frown, resigned look',
      };
  
      const grid: Partial<ExpressionGrid> = {};
  
      for (const emotion of emotions) {
        const emotionPrompt = expressionPrompts[emotion] || `${emotion} expression`;
        const fullPrompt = `${basePrompt}, ${emotionPrompt}`;
  
        console.log(`   Generating: ${emotion}...`);
  
        const result = await this.config.primaryProvider.generateWithIdentity({
          prompt: fullPrompt,
          negativePrompt: '', // FLUX ignores negative prompts
          faceEmbedding: faceEmbedding.vector,
          styleEmbedding: styleEmbedding.vector.length > 0 ? styleEmbedding.vector : undefined,
          params: {
            width: this.settings.defaultWidth,
            height: this.settings.defaultHeight,
            steps: 28, // FLUX quality
            cfgScale: 3.5, // FLUX optimal (NOT 7.5!)
            identityStrength: 0.85,
            styleStrength: 0.3,
          },
        });
  
        // Upload and get thumbnail
        const thumbnailUrl = result.imageUrl; // In production, generate actual thumbnail
  
        (grid as any)[emotion] = ({
          intensity: 1.0 as NormalizedFloat,
          imageUrl: result.imageUrl,
          thumbnailUrl,
          seed: result.seed,
          generatedAt: new Date().toISOString(),
        }) as ExpressionAsset;
  
        console.log(`   âœ… ${emotion} complete (${result.generationTimeMs}ms)`);
      }
  
      return grid as ExpressionGrid;
    }
  
    /**
     * STEP 4: Generate with locked identity
     *
     * Generate any new image using the locked identity.
     * This ensures the face is ALWAYS consistent.
     */
    async generateWithLockedIdentity(
      faceEmbedding: FaceEmbedding,
      prompt: string,
      options?: {
        styleEmbedding?: StyleEmbedding;
        negativePrompt?: string;
        params?: GenerationRequest['params'];
      }
    ): Promise<GenerationResult> {
      return this.config.primaryProvider.generateWithIdentity({
        prompt,
        negativePrompt: options?.negativePrompt || this.getDefaultNegativePrompt('custom'),
        faceEmbedding: faceEmbedding.vector,
        styleEmbedding: options?.styleEmbedding?.vector,
        params: {
          ...options?.params,
          identityStrength: options?.params?.identityStrength ?? 0.85,
        },
      });
    }
  
    /**
     * Build complete Visual DNA from locked identity
     */
    async buildVisualDNA(
      faceEmbedding: FaceEmbedding,
      styleEmbedding: StyleEmbedding,
      expressions: ExpressionGrid,
      stylePreset: string
    ): Promise<VisualDNA> {
      return {
        faceEmbedding,
        styleEmbedding,
        expressions,
        generationConfig: {
          checkpoint: 'flux1-dev-fp8',
          cfgScale: 3.5, // FLUX optimal (NOT 7.5!)
          sampler: 'euler',
          steps: 28, // FLUX quality steps
          identityStrength: 0.85,
          styleStrength: 0.3,
        },
        lockedPrompt: {
          positive: styleEmbedding.stylePrompt || '',
          negative: '', // FLUX ignores negative prompts
        },
      };
    }
  
    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    // PRIVATE HELPERS
    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  
    private buildCharacterPrompt(
      description: string,
      stylePreset: string,
      customAddition?: string
    ): string {
      // Use the Pixar-quality style prompts defined at module level
      const stylePrefix = PIXAR_STYLE_PROMPTS[stylePreset as PixarStylePreset] || PIXAR_STYLE_PROMPTS.hyper_realistic;
      const parts = [stylePrefix, description];

      if (customAddition) {
        parts.push(customAddition);
      }

      return parts.join(', ');
    }
  
    private getDefaultNegativePrompt(stylePreset: string): string {
      // FLUX ignores negative prompts - they can actually HURT quality
      // Return empty string for FLUX model
      return '';
    }
  }
  
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // FACTORY
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  
  /**
   * Create an Identity Lock Pipeline with RunPod
   *
   * Uses RunPod ComfyUI with FLUX for state-of-the-art image generation.
   * No fallbacks - RunPod is our ONLY GPU provider.
   */
  export function createIdentityLockPipeline(options: {
    runpodApiKey?: string;
    runpodEndpointId?: string;
    storage: IdentityLockConfig['storage'];
  }): IdentityLockPipeline {
    // RunPod is required - no fallbacks
    if (!options.runpodApiKey || !options.runpodEndpointId) {
      throw new Error('RunPod API key and endpoint ID are required (RUNPOD_API_KEY, RUNPOD_ENDPOINT_ID)');
    }

    const primaryProvider = new RunPodProvider({
      provider: 'runpod',
      apiKey: options.runpodApiKey,
      baseUrl: options.runpodEndpointId,
    });
    console.log(`[Pipeline] Using RunPod ComfyUI FLUX (${options.runpodEndpointId})`);

    return new IdentityLockPipeline({
      primaryProvider,
      storage: options.storage,
    });
  }